{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'istatapi.base'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0cb3d62717ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mistatapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mISTAT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mistatapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrip_ns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfastcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'istatapi.base'"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from istatapi.base import ISTAT\n",
    "from istatapi.utils import make_tree, strip_ns\n",
    "import pandas as pd\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovery\n",
    "\n",
    "> Functions used to discover and explore the data exposed by ISTAT webservice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module implements functions to discover the data exposed by ISTAT. To do so, `istatapi` make metadata requests to the API endpoints. The `Discovery` module provides useful methods to parse and analyze API metadata responses. It makes use of the library `pandas` and returns data in the `DataFrame` format, making it convenient for interactive and exploratory analysis in Jupyter Notebooks.\n",
    "\n",
    "The main class implemented in the `Discovery` module is `DataSet`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore available datasets\n",
    "\n",
    "In order to understand what data we can retrieve from ISTAT database, the ```discovery``` module implements functions to list all the datasets provided by the API service. Also, the list of datasets can be searched through keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def parse_dataflows(response):\n",
    "    \"\"\"parse the `response` containing all the available datasets and return a list of dataflows.\"\"\"\n",
    "    tree = make_tree(response)\n",
    "    strip_ns(tree)\n",
    "    root = tree.root\n",
    "\n",
    "    dataflows_l = []\n",
    "    for dataflow in root.iter(\"Dataflow\"):\n",
    "        id = dataflow.get(\"id\")\n",
    "        version = dataflow.get(\"version\")\n",
    "        structure_id = [ref.get(\"id\") for ref in dataflow.iter(\"Ref\")][0]\n",
    "\n",
    "        # iter over names and get the descriptions\n",
    "        for name in dataflow.findall(\"Name\"):\n",
    "            lang = name.get(\"{http://www.w3.org/XML/1998/namespace}lang\")\n",
    "            if lang == \"en\":\n",
    "                description_en = name.text\n",
    "            # if lang == 'it':\n",
    "            # description_it = name.text\n",
    "\n",
    "        dataflow_dict = {\n",
    "            \"df_id\": id,\n",
    "            \"version\": version,\n",
    "            \"df_description\": description_en,\n",
    "            # \"description_it\": description_it,\n",
    "            \"df_structure_id\": structure_id,\n",
    "        }\n",
    "\n",
    "        dataflows_l.append(dataflow_dict)\n",
    "\n",
    "    return dataflows_l\n",
    "\n",
    "\n",
    "def all_available(dataframe=True):\n",
    "    \"\"\"Return all available dataflows\"\"\"\n",
    "    path = \"dataflow/IT1\"\n",
    "    client = ISTAT()\n",
    "    response = client._request(path=path)\n",
    "    dataflows = parse_dataflows(response)\n",
    "\n",
    "    if dataframe == True:\n",
    "        dataflows = pd.DataFrame(dataflows)\n",
    "\n",
    "    return dataflows\n",
    "\n",
    "\n",
    "def search_dataset(keyword):\n",
    "    \"\"\"Search available dataflows that contain `keyword`. Return these dataflows in a DataFrame\"\"\"\n",
    "    dataflows = all_available()[\n",
    "        all_available()[\"df_description\"].str.contains(keyword, case=False)\n",
    "    ]\n",
    "    \n",
    "    if len(dataflows) == 0: raise ValueError('No dataset matching `keyword`')\n",
    "\n",
    "    return dataflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to get a full list of the dataflows provided by ISTAT is to call the method `all_available()` which returns a list of all the explorable dataflows, together with their IDs and descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"all_available\" class=\"doc_header\"><code>all_available</code><a href=\"__main__.py#L35\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>all_available</code>(**`dataframe`**=*`True`*)\n",
       "\n",
       "Return all available dataflows"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(all_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_datasets = all_available()\n",
    "available_datasets.head()\n",
    "test_eq(len(available_datasets), 456)\n",
    "test_eq(available_datasets.columns, ['df_id', 'version', 'df_description', 'df_structure_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"search_dataset\" class=\"doc_header\"><code>search_dataset</code><a href=\"__main__.py#L48\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>search_dataset</code>(**`keyword`**)\n",
       "\n",
       "Search available dataflows that contain `keyword`. Return these dataflows in a DataFrame"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(search_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method looks for `keyword` inside all datasets descriptions. By default, the `keyword` needs to be an english word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = search_dataset(keyword=\"Unemployment\")\n",
    "df.head()\n",
    "test_fail(lambda: search_dataset(keyword=\"disoccupazione\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures and Information about available Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API provides a lot of information on its datasets. The `DataSet` class implements methods to retrieve this info. The followings are the main functionalities implemented by the class:\n",
    "\n",
    "1. Find The ID of the ```dataflow``` (dataset) containing the data that needs to be returned\n",
    "2. Display The of the ```dataflow``` we want to query. Dimension is another name for a column or a variable.\n",
    "3. Explain the names of the dimensions.\n",
    "4. display the possible values of the dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataSet(ISTAT):\n",
    "    \"\"\"Class that implements methods to retrieve informations (metadata) about a Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, dataflow_identifier):\n",
    "        super().__init__()\n",
    "        self.resource = \"datastructure\"\n",
    "        self.all_available = all_available()  # df with all the available dataflows\n",
    "        self.identifiers = self.set_identifiers(dataflow_identifier)\n",
    "        self.available_values = self.get_available_values()\n",
    "        self.dimensions = list(self.dimensions_info(description=False).dimension)\n",
    "        self.filters = self.default_filters()\n",
    "        # self.dimensions_values = self.available_dimensions_values()\n",
    "        \n",
    "        # TODO: returning all metadata related to the dataflow contained in 'Header'\n",
    "\n",
    "    def set_identifiers(self, dataflow_identifier):\n",
    "        \"\"\"Take any type of `dataflow_identifier` and return all identifiers in a dictionary\"\"\"\n",
    "        if dataflow_identifier[3] == \"_\":\n",
    "            return self.set_from_id(dataflow_identifier)\n",
    "        elif dataflow_identifier[4] == \"_\":\n",
    "            return self.set_from_structure_id(dataflow_identifier)\n",
    "        else:\n",
    "            if type(dataflow_identifier) == str:\n",
    "                return self.set_from_description(dataflow_identifier)\n",
    "            else:\n",
    "                raise ValueError(dataflow_identifier)\n",
    "\n",
    "    def set_from_id(self, df_id):\n",
    "        mask = self.all_available[\"df_id\"] == df_id\n",
    "        df = self.all_available[mask]\n",
    "        return df.to_dict(orient=\"records\")[0]\n",
    "\n",
    "    def set_from_structure_id(self, df_structure_id):\n",
    "        mask = self.all_available[\"df_structure_id\"] == df_structure_id\n",
    "        df = self.all_available[mask]\n",
    "        return df.to_dict(orient=\"records\")[0]\n",
    "\n",
    "    def set_from_description(self, description):\n",
    "        mask = self.all_available[\"df_description\"] == description\n",
    "        df = self.all_available[mask]\n",
    "        return df.to_dict(orient=\"records\")[0]\n",
    "\n",
    "    def parse_dimensions(self, response):\n",
    "        \"\"\"Parse the `response` containing a dataflow's dimensions and return them in a list\"\"\"\n",
    "        tree = make_tree(response)\n",
    "        strip_ns(tree)\n",
    "        root = tree.root\n",
    "\n",
    "        dimensions_l = []\n",
    "        for dimension in root.iter(\"Dimension\"):\n",
    "            dimension_name = dimension.attrib[\"id\"]\n",
    "\n",
    "            dimension_id = [\n",
    "                enumeration.find(\"Ref\").get(\"id\")\n",
    "                for enumeration in dimension.iter(\"Enumeration\")\n",
    "            ][0]\n",
    "\n",
    "            dimension_dict = {\"dimension\": dimension_name, \"dimension_ID\": dimension_id}\n",
    "\n",
    "            dimensions_l.append(dimension_dict)\n",
    "\n",
    "        return dimensions_l\n",
    "\n",
    "    def dimensions_info(self, dataframe=True, description=True):\n",
    "        \"\"\"Return the dimensions of a specific dataflow and their `descriptions`.\"\"\"\n",
    "        df_structure_id = self.identifiers[\"df_structure_id\"]\n",
    "\n",
    "        path_parts = [self.resource, self.agencyID, df_structure_id]\n",
    "        path = \"/\".join(path_parts)\n",
    "        response = self._request(path=path)\n",
    "        dimensions = self.parse_dimensions(response)\n",
    "\n",
    "        if dataframe == True:\n",
    "            dimensions = pd.DataFrame(dimensions)\n",
    "\n",
    "        if description == True:\n",
    "            dimensions_description = self.dimensions_description(dimensions)\n",
    "            dimensions = dimensions.merge(dimensions_description, on=\"dimension_ID\")\n",
    "\n",
    "        return dimensions\n",
    "\n",
    "    def dimensions_description(self, dimensions):\n",
    "        \"\"\"Return a dataframe with the descriptions of `dimensions`\"\"\"\n",
    "        resource = \"codelist\"\n",
    "        dimensions_l = dimensions.dimension_ID.tolist()\n",
    "        descriptions_l = []\n",
    "\n",
    "        for dimension_id in dimensions_l:\n",
    "            path_parts = [resource, self.agencyID, dimension_id]\n",
    "            path = \"/\".join(path_parts)\n",
    "            response = self._request(path=path)\n",
    "            tree = make_tree(response)\n",
    "            strip_ns(tree)\n",
    "            root = tree.root\n",
    "\n",
    "            description = [x for x in root.iter(\"Codelist\")][0]\n",
    "            # description_it = description.findall('Name')[0].text\n",
    "            description = description.findall(\"Name\")[1].text\n",
    "\n",
    "            description_dict = {\n",
    "                \"dimension_ID\": dimension_id,\n",
    "                \"description\": description,\n",
    "            }\n",
    "            descriptions_l.append(description_dict)\n",
    "\n",
    "        dimensions_descriptions = pd.DataFrame(descriptions_l)\n",
    "\n",
    "        return dimensions_descriptions\n",
    "\n",
    "    def get_available_values(self):\n",
    "        \"\"\"Return a dictionary with available values for each dimension in the DataSet instance\"\"\"\n",
    "        resource = \"availableconstraint\"\n",
    "        df_id = self.identifiers[\"df_id\"]\n",
    "        path_parts = [\n",
    "            resource,\n",
    "            df_id,\n",
    "            \"?references=all&detail=full\",\n",
    "        ]  # TODO: pass them as parameters\n",
    "        path = \"/\".join(path_parts)\n",
    "        response = self._request(path=path)\n",
    "        tree = make_tree(response)\n",
    "        strip_ns(tree)\n",
    "        root = tree.root\n",
    "\n",
    "        dimensions_values = {}\n",
    "\n",
    "        for dimension in root.iter(\"Codelist\"):\n",
    "            dimension_id = dimension.get(\"id\")\n",
    "\n",
    "            values = {}\n",
    "            value_id_l, value_descr_l = [], []\n",
    "\n",
    "            for value in dimension.iter(\"Code\"):\n",
    "                value_id = value.get(\"id\")\n",
    "                value_descr = [name.text for name in value.findall(\"Name\")][1]\n",
    "                value_id_l.append(value_id)\n",
    "                value_descr_l.append(value_descr)\n",
    "\n",
    "            values[\"values_ids\"] = value_id_l\n",
    "            values[\"values_description\"] = value_descr_l\n",
    "            dimensions_values[dimension_id] = values\n",
    "\n",
    "        for dimension_id in list(dimensions_values.keys()):\n",
    "            dimension = self.get_dimension_name(dimension_id)\n",
    "            dimensions_values[dimension] = dimensions_values.pop(dimension_id)\n",
    "\n",
    "        return dimensions_values\n",
    "\n",
    "    def get_dimension_values(self, dimension, dataframe=True):\n",
    "        \"\"\"Return the available values of a single `dimension` in the dataset\"\"\"\n",
    "        dimension_dict = self.available_values[dimension]\n",
    "        dimension_df = pd.DataFrame.from_dict(dimension_dict)\n",
    "        return dimension_df if dataframe else dimension_dict\n",
    "\n",
    "    def get_dimension_name(self, dimension_id):\n",
    "        \"\"\"Convert `dimension_id` to `dimension`\"\"\"\n",
    "        dimensions_df = self.dimensions_info(description=False)\n",
    "        mask = dimensions_df[\"dimension_ID\"] == dimension_id\n",
    "        dimension = dimensions_df[mask][\"dimension\"]\n",
    "        return dimension.values[0]\n",
    "\n",
    "    def default_filters(self):\n",
    "        \"\"\"\"initiate self.filters with default values\"\"\"\n",
    "        default_filters = {}  \n",
    "        # no filter equals all values (default)\n",
    "        for dimension in self.dimensions:\n",
    "            default_filters[dimension] = \".\"\n",
    "        return default_filters\n",
    "\n",
    "    def set_filters(self, **kwargs):\n",
    "        \"\"\"set filters for the dimensions of the dataset by passing dimension_name=value\"\"\"\n",
    "        # add kwargs in case passed\n",
    "        for arg, arg_value in kwargs.items():\n",
    "            self.filters[arg.upper()] = arg_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class takes `df_id`, `df_structure_id` or `df_description` as inputs. These 3 values can be found by using the `all_available()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DataSet(dataflow_identifier=\"151_914\")\n",
    "test_eq(ds.identifiers['df_id'], '151_914')\n",
    "test_eq(ds.identifiers['df_description'], 'Unemployment  rate')\n",
    "test_eq(ds.identifiers['df_structure_id'], 'DCCV_TAXDISOCCU1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can look at the dimensions of a dataflow by simply accessing its attribute `dimensions`. However, we won't have dimensions' descriptions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"DataSet.dimensions_info\" class=\"doc_header\"><code>DataSet.dimensions_info</code><a href=\"__main__.py#L65\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DataSet.dimensions_info</code>(**`dataframe`**=*`True`*, **`description`**=*`True`*)\n",
       "\n",
       "Return the dimensions of a specific dataflow and their `descriptions`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataSet.dimensions_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a look at the dimensions together with their menaing/description, we can use the `dimension_info` function. It will return an easy to read pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dimension</th>\n",
       "      <th>dimension_ID</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FREQ</td>\n",
       "      <td>CL_FREQ</td>\n",
       "      <td>Frequency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CITTADINANZA</td>\n",
       "      <td>CL_CITTADINANZA</td>\n",
       "      <td>Citizenship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DURATA_DISOCCUPAZ</td>\n",
       "      <td>CL_DURATA</td>\n",
       "      <td>Duration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CLASSE_ETA</td>\n",
       "      <td>CL_ETA1</td>\n",
       "      <td>Age class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ITTER107</td>\n",
       "      <td>CL_ITTER107</td>\n",
       "      <td>Territory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SESSO</td>\n",
       "      <td>CL_SEXISTAT1</td>\n",
       "      <td>Gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TIPO_DATO</td>\n",
       "      <td>CL_TIPO_DATO_FOL</td>\n",
       "      <td>Data type FOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TITOLO_STUDIO</td>\n",
       "      <td>CL_TITOLO_STUDIO</td>\n",
       "      <td>Level of education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dimension      dimension_ID         description\n",
       "0               FREQ           CL_FREQ           Frequency\n",
       "1       CITTADINANZA   CL_CITTADINANZA         Citizenship\n",
       "2  DURATA_DISOCCUPAZ         CL_DURATA            Duration\n",
       "3         CLASSE_ETA           CL_ETA1           Age class\n",
       "4           ITTER107       CL_ITTER107           Territory\n",
       "5              SESSO      CL_SEXISTAT1              Gender\n",
       "6          TIPO_DATO  CL_TIPO_DATO_FOL       Data type FOL\n",
       "7      TITOLO_STUDIO  CL_TITOLO_STUDIO  Level of education"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimensions_df = ds.dimensions_info()\n",
    "test_eq(dimensions_df.columns, ['dimension', 'dimension_ID', 'description'])\n",
    "dimensions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values that the different dimensions can take can also be explored. The `available_values` attribute contains a dictionary with the dimensions of the dataset as keys. The values of the dictionary are themselves dictionaries which can be accessed through the `values_ids` and `values_description` keys. The former key returns an ID of the dimension's values, the latter a description of these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_dict = ds.available_values\n",
    "test_eq(isinstance(values_dict, dict), True)\n",
    "test_eq(list(values_dict.keys()).sort(), ds.dimensions.sort())\n",
    "test_eq(values_dict['DURATA_DISOCCUPAZ']['values_ids'], ['TOTAL', 'M_GE12'])\n",
    "test_eq(values_dict['DURATA_DISOCCUPAZ']['values_description'], ['total', '12 mesi e più'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"DataSet.get_dimension_values\" class=\"doc_header\"><code>DataSet.get_dimension_values</code><a href=\"__main__.py#L150\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DataSet.get_dimension_values</code>(**`dimension`**, **`dataframe`**=*`True`*)\n",
       "\n",
       "Return the available values of a single `dimension` in the dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataSet.get_dimension_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values_ids</th>\n",
       "      <th>values_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOTAL</td>\n",
       "      <td>total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M_GE12</td>\n",
       "      <td>12 mesi e più</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  values_ids values_description\n",
       "0      TOTAL              total\n",
       "1     M_GE12      12 mesi e più"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.get_dimension_values('DURATA_DISOCCUPAZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"DataSet.set_filters\" class=\"doc_header\"><code>DataSet.set_filters</code><a href=\"__main__.py#L171\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DataSet.set_filters</code>(**\\*\\*`kwargs`**)\n",
       "\n",
       "set filters for the dimensions of the dataset by passing dimension_name=value"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataSet.set_filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `DataSet.set_filters()` we can filter the dimensions of the dataset by passing the values that we want to filter for. The dataset will then only return data containing our filters. A dictionary with the selected filters is contained in the attribute `DataSet.filters`.\n",
    "\n",
    "**Note** that the arguments of `DataSet.set_filters` are lower case letters, but in `DataSet.filters` they are converted to upper case to be consistent with dimension names on ISTAT API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz = DataSet(dataflow_identifier=\"139_176\")\n",
    "dz.set_filters(freq=\"M\", tipo_dato=[\"ISAV\", \"ESAV\"], paese_partner=\"WORLD\")\n",
    "\n",
    "test_eq(dz.filters['FREQ'], 'M')\n",
    "test_eq(dz.filters['TIPO_DATO'], [\"ISAV\", \"ESAV\"])\n",
    "test_fail(lambda: dz.filters['freq']) #the filter is not saved in lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_base.ipynb.\n",
      "Converted 01_discovery.ipynb.\n",
      "Converted 02_utils.ipynb.\n",
      "Converted 03_retrieval.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "export.notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
