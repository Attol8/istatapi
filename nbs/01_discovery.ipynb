{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from istatapi.base import ISTAT\n",
    "from istatapi.utils import make_tree, strip_ns\n",
    "import pandas as pd\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`<<<<<<< HEAD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`=======`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from istatapi.base import ISTAT\n",
    "from istatapi.utils import make_tree, strip_ns\n",
    "import pandas as pd\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from istatapi.base import ISTAT\n",
    "from istatapi.utils import make_tree, strip_ns\n",
    "import pandas as pd\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`>>>>>>> c2fb413 (update fastai and fastcore)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovery\n",
    "\n",
    "> Functions used to discover and explore the data exposed by ISTAT webservice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module implements functions to discover the data exposed by ISTAT. To do so, `istatapi` make metadata requests to the API endpoints. The `Discovery` module provides useful methods to parse and analyze API metadata responses. It makes use of the library `pandas` and returns data in the `DataFrame` format, making it convenient for interactive and exploratory analysis in Jupyter Notebooks.\n",
    "\n",
    "The main class implemented in the `Discovery` module is `DataSet`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def parse_dataflows(response):\n",
    "    \"\"\"parse the `response` containing all the available datasets and return a list of dataflows.\"\"\"\n",
    "    tree = make_tree(response)\n",
    "    strip_ns(tree)\n",
    "    root = tree.root\n",
    "\n",
    "    dataflows_l = []\n",
    "    for dataflow in root.iter(\"Dataflow\"):\n",
    "        id = dataflow.get(\"id\")\n",
    "        version = dataflow.get(\"version\")\n",
    "        structure_id = [ref.get(\"id\") for ref in dataflow.iter(\"Ref\")][0]\n",
    "\n",
    "        # iter over names and get the descriptions\n",
    "        for name in dataflow.findall(\"Name\"):\n",
    "            lang = name.get(\"{http://www.w3.org/XML/1998/namespace}lang\")\n",
    "            if lang == \"en\":\n",
    "                description_en = name.text\n",
    "            # if lang == 'it':\n",
    "            # description_it = name.text\n",
    "\n",
    "        dataflow_dict = {\n",
    "            \"df_id\": id,\n",
    "            \"version\": version,\n",
    "            \"df_description\": description_en,\n",
    "            # \"description_it\": description_it,\n",
    "            \"df_structure_id\": structure_id,\n",
    "        }\n",
    "\n",
    "        dataflows_l.append(dataflow_dict)\n",
    "\n",
    "    return dataflows_l\n",
    "\n",
    "\n",
    "def all_available(dataframe=True):\n",
    "    \"\"\"Return all available dataflows\"\"\"\n",
    "    path = \"dataflow/IT1\"\n",
    "    client = ISTAT()\n",
    "    response = client._request(path=path)\n",
    "    dataflows = parse_dataflows(response)\n",
    "\n",
    "    if dataframe == True:\n",
    "        dataflows = pd.DataFrame(dataflows)\n",
    "\n",
    "    return dataflows\n",
    "\n",
    "\n",
    "def search_dataset(keyword):\n",
    "    \"\"\"Search available dataflows that contain `keyword`. Return these dataflows in a DataFrame\"\"\"\n",
    "    dataflows = all_available()[\n",
    "        all_available()[\"df_description\"].str.contains(keyword, case=False)\n",
    "    ]\n",
    "    \n",
    "    if len(dataflows) == 0: raise ValueError('No dataset matching `keyword`')\n",
    "\n",
    "    return dataflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_dataflows(response):\n",
    "    \"\"\"parse the `response` containing all the available datasets and return a list of dataflows.\"\"\"\n",
    "    tree = make_tree(response)\n",
    "    strip_ns(tree)\n",
    "    root = tree.root\n",
    "\n",
    "    dataflows_l = []\n",
    "    for dataflow in root.iter(\"Dataflow\"):\n",
    "        id = dataflow.get(\"id\")\n",
    "        version = dataflow.get(\"version\")\n",
    "        structure_id = [ref.get(\"id\") for ref in dataflow.iter(\"Ref\")][0]\n",
    "\n",
    "        # iter over names and get the descriptions\n",
    "        for name in dataflow.findall(\"Name\"):\n",
    "            lang = name.get(\"{http://www.w3.org/XML/1998/namespace}lang\")\n",
    "            if lang == \"en\":\n",
    "                description_en = name.text\n",
    "            # if lang == 'it':\n",
    "            # description_it = name.text\n",
    "\n",
    "        dataflow_dict = {\n",
    "            \"df_id\": id,\n",
    "            \"version\": version,\n",
    "            \"df_description\": description_en,\n",
    "            # \"description_it\": description_it,\n",
    "            \"df_structure_id\": structure_id,\n",
    "        }\n",
    "\n",
    "        dataflows_l.append(dataflow_dict)\n",
    "\n",
    "    return dataflows_l\n",
    "\n",
    "\n",
    "def all_available(dataframe=True):\n",
    "    \"\"\"Return all available dataflows\"\"\"\n",
    "    path = \"dataflow/IT1\"\n",
    "    client = ISTAT()\n",
    "    response = client._request(path=path)\n",
    "    dataflows = parse_dataflows(response)\n",
    "\n",
    "    if dataframe == True:\n",
    "        dataflows = pd.DataFrame(dataflows)\n",
    "\n",
    "    return dataflows\n",
    "\n",
    "\n",
    "def search_dataset(keyword):\n",
    "    \"\"\"Search available dataflows that contain `keyword`. Return these dataflows in a DataFrame\"\"\"\n",
    "    dataflows = all_available()[\n",
    "        all_available()[\"df_description\"].str.contains(keyword, case=False)\n",
    "    ]\n",
    "    \n",
    "    if len(dataflows) == 0: raise ValueError('No dataset matching `keyword`')\n",
    "\n",
    "    return dataflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to get a full list of the dataflows provided by ISTAT is to call the method `all_available()` which returns a list of all the explorable dataflows, together with their IDs and descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### all_available\n",
       "\n",
       ">      all_available (dataframe=True)\n",
       "\n",
       "Return all available dataflows"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### all_available\n",
       "\n",
       ">      all_available (dataframe=True)\n",
       "\n",
       "Return all available dataflows"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(all_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df_id</th>\n",
       "      <th>version</th>\n",
       "      <th>df_description</th>\n",
       "      <th>df_structure_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101_1015</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Crops</td>\n",
       "      <td>DCSP_COLTIVAZIONI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101_1030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PDO, PGI and TSG quality products</td>\n",
       "      <td>DCSP_DOPIGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101_1033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>slaughtering</td>\n",
       "      <td>DCSP_MACELLAZIONI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101_1039</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Agritourism - municipalities</td>\n",
       "      <td>DCSP_AGRITURISMO_COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101_1077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PDO, PGI and TSG products:  operators - munici...</td>\n",
       "      <td>DCSP_DOPIGP_COM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      df_id version                                     df_description  \\\n",
       "0  101_1015     1.3                                              Crops   \n",
       "1  101_1030     1.0                  PDO, PGI and TSG quality products   \n",
       "2  101_1033     1.0                                       slaughtering   \n",
       "3  101_1039     1.2                       Agritourism - municipalities   \n",
       "4  101_1077     1.0  PDO, PGI and TSG products:  operators - munici...   \n",
       "\n",
       "        df_structure_id  \n",
       "0     DCSP_COLTIVAZIONI  \n",
       "1           DCSP_DOPIGP  \n",
       "2     DCSP_MACELLAZIONI  \n",
       "3  DCSP_AGRITURISMO_COM  \n",
       "4       DCSP_DOPIGP_COM  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_datasets = all_available()\n",
    "available_datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of available datasets: 501\n"
     ]
    }
   ],
   "source": [
    "print(f'number of available datasets: {len(available_datasets)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(available_datasets.columns, ['df_id', 'version', 'df_description', 'df_structure_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### search_dataset\n",
       "\n",
       ">      search_dataset (keyword)\n",
       "\n",
       "Search available dataflows that contain `keyword`. Return these dataflows in a DataFrame"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### search_dataset\n",
       "\n",
       ">      search_dataset (keyword)\n",
       "\n",
       "Search available dataflows that contain `keyword`. Return these dataflows in a DataFrame"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(search_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method looks for `keyword` inside all datasets descriptions. By default, the `keyword` needs to be an english word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df_id</th>\n",
       "      <th>version</th>\n",
       "      <th>df_description</th>\n",
       "      <th>df_structure_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>168_261</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Hicp - at constant tax rates annual data(base ...</td>\n",
       "      <td>DCSP_IPCATC2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>168_306</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Hicp - at constant tax rates monthly data (bas...</td>\n",
       "      <td>DCSP_IPCATC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>168_756</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Hicp - at constant tax rates monthly data (bas...</td>\n",
       "      <td>DCSP_IPCATC1B2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>168_757</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Hicp- at constant tax rates annual data (base ...</td>\n",
       "      <td>DCSP_IPCATC2B2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>30_1008</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Irpef taxable incomes (Ipef) - municipalities</td>\n",
       "      <td>MEF_REDDITIIRPEF_COM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       df_id version                                     df_description  \\\n",
       "168  168_261     1.1  Hicp - at constant tax rates annual data(base ...   \n",
       "169  168_306     1.2  Hicp - at constant tax rates monthly data (bas...   \n",
       "172  168_756     1.4  Hicp - at constant tax rates monthly data (bas...   \n",
       "173  168_757     1.1  Hicp- at constant tax rates annual data (base ...   \n",
       "265  30_1008     1.1      Irpef taxable incomes (Ipef) - municipalities   \n",
       "\n",
       "          df_structure_id  \n",
       "168          DCSP_IPCATC2  \n",
       "169          DCSP_IPCATC1  \n",
       "172     DCSP_IPCATC1B2015  \n",
       "173     DCSP_IPCATC2B2015  \n",
       "265  MEF_REDDITIIRPEF_COM  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = search_dataset(keyword=\"Tax\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fail(lambda: search_dataset(keyword=\"disoccupazione\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structures and Information about available Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class DataSet(ISTAT):\n",
    "    \"\"\"Class that implements methods to retrieve informations (metadata) about a Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, dataflow_identifier):\n",
    "        super().__init__()\n",
    "        self.resource = \"datastructure\"\n",
    "        self.all_available = all_available()  # df with all the available dataflows\n",
    "        self.identifiers = self.set_identifiers(dataflow_identifier)\n",
    "        self.available_values = self.get_available_values()\n",
    "        self.dimensions = list(self.dimensions_info(description=False).dimension)\n",
    "        self.filters = self.default_filters()\n",
    "        # self.dimensions_values = self.available_dimensions_values()\n",
    "        \n",
    "        # TODO: returning all metadata related to the dataflow contained in 'Header'\n",
    "\n",
    "    def set_identifiers(self, dataflow_identifier):\n",
    "        \"\"\"Take any type of `dataflow_identifier` and return all identifiers in a dictionary\"\"\"\n",
    "        if dataflow_identifier[3] == \"_\":\n",
    "            return self.set_from_id(dataflow_identifier)\n",
    "        elif dataflow_identifier[4] == \"_\":\n",
    "            return self.set_from_structure_id(dataflow_identifier)\n",
    "        else:\n",
    "            if type(dataflow_identifier) == str:\n",
    "                return self.set_from_description(dataflow_identifier)\n",
    "            else:\n",
    "                raise ValueError(dataflow_identifier)\n",
    "\n",
    "    def set_from_id(self, df_id):\n",
    "        mask = self.all_available[\"df_id\"] == df_id\n",
    "        df = self.all_available[mask]\n",
    "        return df.to_dict(orient=\"records\")[0]\n",
    "\n",
    "    def set_from_structure_id(self, df_structure_id):\n",
    "        mask = self.all_available[\"df_structure_id\"] == df_structure_id\n",
    "        df = self.all_available[mask]\n",
    "        return df.to_dict(orient=\"records\")[0]\n",
    "\n",
    "    def set_from_description(self, description):\n",
    "        mask = self.all_available[\"df_description\"] == description\n",
    "        df = self.all_available[mask]\n",
    "        return df.to_dict(orient=\"records\")[0]\n",
    "\n",
    "    def parse_dimensions(self, response):\n",
    "        \"\"\"Parse the `response` containing a dataflow's dimensions and return them in a list\"\"\"\n",
    "        tree = make_tree(response)\n",
    "        strip_ns(tree)\n",
    "        root = tree.root\n",
    "\n",
    "        dimensions_l = []\n",
    "        for dimension in root.iter(\"Dimension\"):\n",
    "            dimension_name = dimension.attrib[\"id\"]\n",
    "\n",
    "            dimension_id = [\n",
    "                enumeration.find(\"Ref\").get(\"id\")\n",
    "                for enumeration in dimension.iter(\"Enumeration\")\n",
    "            ][0]\n",
    "\n",
    "            dimension_dict = {\"dimension\": dimension_name, \"dimension_ID\": dimension_id}\n",
    "\n",
    "            dimensions_l.append(dimension_dict)\n",
    "\n",
    "        return dimensions_l\n",
    "\n",
    "    def dimensions_info(self, dataframe=True, description=True):\n",
    "        \"\"\"Return the dimensions of a specific dataflow and their `descriptions`.\"\"\"\n",
    "        df_structure_id = self.identifiers[\"df_structure_id\"]\n",
    "\n",
    "        path_parts = [self.resource, self.agencyID, df_structure_id]\n",
    "        path = \"/\".join(path_parts)\n",
    "        response = self._request(path=path)\n",
    "        dimensions = self.parse_dimensions(response)\n",
    "\n",
    "        if dataframe == True:\n",
    "            dimensions = pd.DataFrame(dimensions)\n",
    "\n",
    "        if description == True:\n",
    "            dimensions_description = self.dimensions_description(dimensions)\n",
    "            dimensions = dimensions.merge(dimensions_description, on=\"dimension_ID\")\n",
    "\n",
    "        return dimensions\n",
    "\n",
    "    def dimensions_description(self, dimensions):\n",
    "        \"\"\"Return a dataframe with the descriptions of `dimensions`\"\"\"\n",
    "        resource = \"codelist\"\n",
    "        dimensions_l = dimensions.dimension_ID.tolist()\n",
    "        descriptions_l = []\n",
    "\n",
    "        for dimension_id in dimensions_l:\n",
    "            path_parts = [resource, self.agencyID, dimension_id]\n",
    "            path = \"/\".join(path_parts)\n",
    "            response = self._request(path=path)\n",
    "            tree = make_tree(response)\n",
    "            strip_ns(tree)\n",
    "            root = tree.root\n",
    "\n",
    "            description = [x for x in root.iter(\"Codelist\")][0]\n",
    "            # description_it = description.findall('Name')[0].text\n",
    "            description = description.findall(\"Name\")[1].text\n",
    "\n",
    "            description_dict = {\n",
    "                \"dimension_ID\": dimension_id,\n",
    "                \"description\": description,\n",
    "            }\n",
    "            descriptions_l.append(description_dict)\n",
    "\n",
    "        dimensions_descriptions = pd.DataFrame(descriptions_l)\n",
    "\n",
    "        return dimensions_descriptions\n",
    "\n",
    "    def get_available_values(self):\n",
    "        \"\"\"Return a dictionary with available values for each dimension in the DataSet instance\"\"\"\n",
    "        resource = \"availableconstraint\"\n",
    "        df_id = self.identifiers[\"df_id\"]\n",
    "        path_parts = [\n",
    "            resource,\n",
    "            df_id,\n",
    "            \"?references=all&detail=full\",\n",
    "        ]  # TODO: pass them as parameters\n",
    "        path = \"/\".join(path_parts)\n",
    "        response = self._request(path=path)\n",
    "        tree = make_tree(response)\n",
    "        strip_ns(tree)\n",
    "        root = tree.root\n",
    "\n",
    "        dimensions_values = {}\n",
    "\n",
    "        for dimension in root.iter(\"Codelist\"):\n",
    "            dimension_id = dimension.get(\"id\")\n",
    "\n",
    "            values = {}\n",
    "            value_id_l, value_descr_l = [], []\n",
    "\n",
    "            for value in dimension.iter(\"Code\"):\n",
    "                value_id = value.get(\"id\")\n",
    "                value_descr = [name.text for name in value.findall(\"Name\")][1]\n",
    "                value_id_l.append(value_id)\n",
    "                value_descr_l.append(value_descr)\n",
    "\n",
    "            values[\"values_ids\"] = value_id_l\n",
    "            values[\"values_description\"] = value_descr_l\n",
    "            dimensions_values[dimension_id] = values\n",
    "\n",
    "        for dimension_id in list(dimensions_values.keys()):\n",
    "            dimension = self.get_dimension_name(dimension_id)\n",
    "            dimensions_values[dimension] = dimensions_values.pop(dimension_id)\n",
    "\n",
    "        return dimensions_values\n",
    "\n",
    "    def get_dimension_values(self, dimension, dataframe=True):\n",
    "        \"\"\"Return the available values of a single `dimension` in the dataset\"\"\"\n",
    "        dimension_dict = self.available_values[dimension]\n",
    "        dimension_df = pd.DataFrame.from_dict(dimension_dict)\n",
    "        return dimension_df if dataframe else dimension_dict\n",
    "\n",
    "    def get_dimension_name(self, dimension_id):\n",
    "        \"\"\"Convert `dimension_id` to `dimension`\"\"\"\n",
    "        dimensions_df = self.dimensions_info(description=False)\n",
    "        mask = dimensions_df[\"dimension_ID\"] == dimension_id\n",
    "        dimension = dimensions_df[mask][\"dimension\"]\n",
    "        return dimension.values[0]\n",
    "\n",
    "    def default_filters(self):\n",
    "        \"\"\"\"initiate self.filters with default values\"\"\"\n",
    "        default_filters = {}  \n",
    "        # no filter equals all values (default)\n",
    "        for dimension in self.dimensions:\n",
    "            default_filters[dimension] = \".\"\n",
    "        return default_filters\n",
    "\n",
    "    def set_filters(self, **kwargs):\n",
    "        \"\"\"set filters for the dimensions of the dataset by passing dimension_name=value\"\"\"\n",
    "        # add kwargs in case passed\n",
    "        for arg, arg_value in kwargs.items():\n",
    "            self.filters[arg.upper()] = arg_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DataSet(ISTAT):\n",
    "    \"\"\"Class that implements methods to retrieve informations (metadata) about a Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, dataflow_identifier):\n",
    "        super().__init__()\n",
    "        self.resource = \"datastructure\"\n",
    "        self.all_available = all_available()  # df with all the available dataflows\n",
    "        self.identifiers = self.set_identifiers(dataflow_identifier)\n",
    "        self.available_values = self.get_available_values()\n",
    "        self.dimensions = list(self.dimensions_info(description=False).dimension)\n",
    "        self.filters = self.default_filters()\n",
    "        # self.dimensions_values = self.available_dimensions_values()\n",
    "        \n",
    "        # TODO: returning all metadata related to the dataflow contained in 'Header'\n",
    "\n",
    "    def set_identifiers(self, dataflow_identifier):\n",
    "        \"\"\"Take any type of `dataflow_identifier` and return all identifiers in a dictionary\"\"\"\n",
    "        if dataflow_identifier[3] == \"_\":\n",
    "            return self.set_from_id(dataflow_identifier)\n",
    "        elif dataflow_identifier[4] == \"_\":\n",
    "            return self.set_from_structure_id(dataflow_identifier)\n",
    "        else:\n",
    "            if type(dataflow_identifier) == str:\n",
    "                return self.set_from_description(dataflow_identifier)\n",
    "            else:\n",
    "                raise ValueError(dataflow_identifier)\n",
    "\n",
    "    def set_from_id(self, df_id):\n",
    "        mask = self.all_available[\"df_id\"] == df_id\n",
    "        df = self.all_available[mask]\n",
    "        return df.to_dict(orient=\"records\")[0]\n",
    "\n",
    "    def set_from_structure_id(self, df_structure_id):\n",
    "        mask = self.all_available[\"df_structure_id\"] == df_structure_id\n",
    "        df = self.all_available[mask]\n",
    "        return df.to_dict(orient=\"records\")[0]\n",
    "\n",
    "    def set_from_description(self, description):\n",
    "        mask = self.all_available[\"df_description\"] == description\n",
    "        df = self.all_available[mask]\n",
    "        return df.to_dict(orient=\"records\")[0]\n",
    "\n",
    "    def parse_dimensions(self, response):\n",
    "        \"\"\"Parse the `response` containing a dataflow's dimensions and return them in a list\"\"\"\n",
    "        tree = make_tree(response)\n",
    "        strip_ns(tree)\n",
    "        root = tree.root\n",
    "\n",
    "        dimensions_l = []\n",
    "        for dimension in root.iter(\"Dimension\"):\n",
    "            dimension_name = dimension.attrib[\"id\"]\n",
    "\n",
    "            dimension_id = [\n",
    "                enumeration.find(\"Ref\").get(\"id\")\n",
    "                for enumeration in dimension.iter(\"Enumeration\")\n",
    "            ][0]\n",
    "\n",
    "            dimension_dict = {\"dimension\": dimension_name, \"dimension_ID\": dimension_id}\n",
    "\n",
    "            dimensions_l.append(dimension_dict)\n",
    "\n",
    "        return dimensions_l\n",
    "\n",
    "    def dimensions_info(self, dataframe=True, description=True):\n",
    "        \"\"\"Return the dimensions of a specific dataflow and their `descriptions`.\"\"\"\n",
    "        df_structure_id = self.identifiers[\"df_structure_id\"]\n",
    "\n",
    "        path_parts = [self.resource, self.agencyID, df_structure_id]\n",
    "        path = \"/\".join(path_parts)\n",
    "        response = self._request(path=path)\n",
    "        dimensions = self.parse_dimensions(response)\n",
    "\n",
    "        if dataframe == True:\n",
    "            dimensions = pd.DataFrame(dimensions)\n",
    "\n",
    "        if description == True:\n",
    "            dimensions_description = self.dimensions_description(dimensions)\n",
    "            dimensions = dimensions.merge(dimensions_description, on=\"dimension_ID\")\n",
    "\n",
    "        return dimensions\n",
    "\n",
    "    def dimensions_description(self, dimensions):\n",
    "        \"\"\"Return a dataframe with the descriptions of `dimensions`\"\"\"\n",
    "        resource = \"codelist\"\n",
    "        dimensions_l = dimensions.dimension_ID.tolist()\n",
    "        descriptions_l = []\n",
    "\n",
    "        for dimension_id in dimensions_l:\n",
    "            path_parts = [resource, self.agencyID, dimension_id]\n",
    "            path = \"/\".join(path_parts)\n",
    "            response = self._request(path=path)\n",
    "            tree = make_tree(response)\n",
    "            strip_ns(tree)\n",
    "            root = tree.root\n",
    "\n",
    "            description = [x for x in root.iter(\"Codelist\")][0]\n",
    "            # description_it = description.findall('Name')[0].text\n",
    "            description = description.findall(\"Name\")[1].text\n",
    "\n",
    "            description_dict = {\n",
    "                \"dimension_ID\": dimension_id,\n",
    "                \"description\": description,\n",
    "            }\n",
    "            descriptions_l.append(description_dict)\n",
    "\n",
    "        dimensions_descriptions = pd.DataFrame(descriptions_l)\n",
    "\n",
    "        return dimensions_descriptions\n",
    "\n",
    "    def get_available_values(self):\n",
    "        \"\"\"Return a dictionary with available values for each dimension in the DataSet instance\"\"\"\n",
    "        resource = \"availableconstraint\"\n",
    "        df_id = self.identifiers[\"df_id\"]\n",
    "        path_parts = [\n",
    "            resource,\n",
    "            df_id,\n",
    "            \"?references=all&detail=full\",\n",
    "        ]  # TODO: pass them as parameters\n",
    "        path = \"/\".join(path_parts)\n",
    "        response = self._request(path=path)\n",
    "        tree = make_tree(response)\n",
    "        strip_ns(tree)\n",
    "        root = tree.root\n",
    "\n",
    "        dimensions_values = {}\n",
    "\n",
    "        for dimension in root.iter(\"Codelist\"):\n",
    "            dimension_id = dimension.get(\"id\")\n",
    "\n",
    "            values = {}\n",
    "            value_id_l, value_descr_l = [], []\n",
    "\n",
    "            for value in dimension.iter(\"Code\"):\n",
    "                value_id = value.get(\"id\")\n",
    "                value_descr = [name.text for name in value.findall(\"Name\")][1]\n",
    "                value_id_l.append(value_id)\n",
    "                value_descr_l.append(value_descr)\n",
    "\n",
    "            values[\"values_ids\"] = value_id_l\n",
    "            values[\"values_description\"] = value_descr_l\n",
    "            dimensions_values[dimension_id] = values\n",
    "\n",
    "        for dimension_id in list(dimensions_values.keys()):\n",
    "            dimension = self.get_dimension_name(dimension_id)\n",
    "            dimensions_values[dimension] = dimensions_values.pop(dimension_id)\n",
    "\n",
    "        return dimensions_values\n",
    "\n",
    "    def get_dimension_values(self, dimension, dataframe=True):\n",
    "        \"\"\"Return the available values of a single `dimension` in the dataset\"\"\"\n",
    "        dimension_dict = self.available_values[dimension]\n",
    "        dimension_df = pd.DataFrame.from_dict(dimension_dict)\n",
    "        return dimension_df if dataframe else dimension_dict\n",
    "\n",
    "    def get_dimension_name(self, dimension_id):\n",
    "        \"\"\"Convert `dimension_id` to `dimension`\"\"\"\n",
    "        dimensions_df = self.dimensions_info(description=False)\n",
    "        mask = dimensions_df[\"dimension_ID\"] == dimension_id\n",
    "        dimension = dimensions_df[mask][\"dimension\"]\n",
    "        return dimension.values[0]\n",
    "\n",
    "    def default_filters(self):\n",
    "        \"\"\"\"initiate self.filters with default values\"\"\"\n",
    "        default_filters = {}  \n",
    "        # no filter equals all values (default)\n",
    "        for dimension in self.dimensions:\n",
    "            default_filters[dimension] = \".\"\n",
    "        return default_filters\n",
    "\n",
    "    def set_filters(self, **kwargs):\n",
    "        \"\"\"set filters for the dimensions of the dataset by passing dimension_name=value\"\"\"\n",
    "        # add kwargs in case passed\n",
    "        for arg, arg_value in kwargs.items():\n",
    "            self.filters[arg.upper()] = arg_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class takes `df_id`, `df_structure_id` or `df_description` as inputs. These 3 values can be found by using the `all_available()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DataSet(dataflow_identifier=\"151_914\")\n",
    "test_eq(ds.identifiers['df_id'], '151_914')\n",
    "test_eq(ds.identifiers['df_description'], 'Unemployment  rate')\n",
    "test_eq(ds.identifiers['df_structure_id'], 'DCCV_TAXDISOCCU1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can look at the dimensions of a dataflow by simply accessing its attribute `dimensions`. However, we won't have dimensions' descriptions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### DataSet.dimensions_info\n",
       "\n",
       ">      DataSet.dimensions_info (dataframe=True, description=True)\n",
       "\n",
       "Return the dimensions of a specific dataflow and their `descriptions`."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### DataSet.dimensions_info\n",
       "\n",
       ">      DataSet.dimensions_info (dataframe=True, description=True)\n",
       "\n",
       "Return the dimensions of a specific dataflow and their `descriptions`."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DataSet.dimensions_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a look at the dimensions together with their menaing/description, we can use the `dimension_info` function. It will return an easy to read pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dimension</th>\n",
       "      <th>dimension_ID</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FREQ</td>\n",
       "      <td>CL_FREQ</td>\n",
       "      <td>Frequency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CITTADINANZA</td>\n",
       "      <td>CL_CITTADINANZA</td>\n",
       "      <td>Citizenship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DURATA_DISOCCUPAZ</td>\n",
       "      <td>CL_DURATA</td>\n",
       "      <td>Duration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CLASSE_ETA</td>\n",
       "      <td>CL_ETA1</td>\n",
       "      <td>Age class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ITTER107</td>\n",
       "      <td>CL_ITTER107</td>\n",
       "      <td>Territory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SESSO</td>\n",
       "      <td>CL_SEXISTAT1</td>\n",
       "      <td>Gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TIPO_DATO</td>\n",
       "      <td>CL_TIPO_DATO_FOL</td>\n",
       "      <td>Data type FOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TITOLO_STUDIO</td>\n",
       "      <td>CL_TITOLO_STUDIO</td>\n",
       "      <td>Level of education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dimension      dimension_ID         description\n",
       "0               FREQ           CL_FREQ           Frequency\n",
       "1       CITTADINANZA   CL_CITTADINANZA         Citizenship\n",
       "2  DURATA_DISOCCUPAZ         CL_DURATA            Duration\n",
       "3         CLASSE_ETA           CL_ETA1           Age class\n",
       "4           ITTER107       CL_ITTER107           Territory\n",
       "5              SESSO      CL_SEXISTAT1              Gender\n",
       "6          TIPO_DATO  CL_TIPO_DATO_FOL       Data type FOL\n",
       "7      TITOLO_STUDIO  CL_TITOLO_STUDIO  Level of education"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimensions_df = ds.dimensions_info()\n",
    "test_eq(dimensions_df.columns, ['dimension', 'dimension_ID', 'description'])\n",
    "dimensions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values that the different dimensions can take can also be explored. The `available_values` attribute contains a dictionary with the dimensions of the dataset as keys. The values of the dictionary are themselves dictionaries which can be accessed through the `values_ids` and `values_description` keys. The former key returns an ID of the dimension's values, the latter a description of these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_dict = ds.available_values\n",
    "test_eq(isinstance(values_dict, dict), True)\n",
    "test_eq(list(values_dict.keys()).sort(), ds.dimensions.sort())\n",
    "test_eq(values_dict['DURATA_DISOCCUPAZ']['values_ids'], ['TOTAL', 'M_GE12'])\n",
    "test_eq(values_dict['DURATA_DISOCCUPAZ']['values_description'], ['total', '12 months and over'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### DataSet.get_dimension_values\n",
       "\n",
       ">      DataSet.get_dimension_values (dimension, dataframe=True)\n",
       "\n",
       "Return the available values of a single `dimension` in the dataset"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### DataSet.get_dimension_values\n",
       "\n",
       ">      DataSet.get_dimension_values (dimension, dataframe=True)\n",
       "\n",
       "Return the available values of a single `dimension` in the dataset"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DataSet.get_dimension_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values_ids</th>\n",
       "      <th>values_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOTAL</td>\n",
       "      <td>total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M_GE12</td>\n",
       "      <td>12 months and over</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  values_ids  values_description\n",
       "0      TOTAL               total\n",
       "1     M_GE12  12 months and over"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.get_dimension_values('DURATA_DISOCCUPAZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### DataSet.set_filters\n",
       "\n",
       ">      DataSet.set_filters (**kwargs)\n",
       "\n",
       "set filters for the dimensions of the dataset by passing dimension_name=value"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### DataSet.set_filters\n",
       "\n",
       ">      DataSet.set_filters (**kwargs)\n",
       "\n",
       "set filters for the dimensions of the dataset by passing dimension_name=value"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DataSet.set_filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `DataSet.set_filters()` we can filter the dimensions of the dataset by passing the values that we want to filter for. The dataset will then only return data containing our filters. A dictionary with the selected filters is contained in the attribute `DataSet.filters`.\n",
    "\n",
    "**Note** that the arguments of `DataSet.set_filters` are lower case letters, but in `DataSet.filters` they are converted to upper case to be consistent with dimension names on ISTAT API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz = DataSet(dataflow_identifier=\"139_176\")\n",
    "dz.set_filters(freq=\"M\", tipo_dato=[\"ISAV\", \"ESAV\"], paese_partner=\"WORLD\")\n",
    "\n",
    "test_eq(dz.filters['FREQ'], 'M')\n",
    "test_eq(dz.filters['TIPO_DATO'], [\"ISAV\", \"ESAV\"])\n",
    "test_fail(lambda: dz.filters['freq']) #the filter is not saved in lower case"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
